{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "087e9e46",
   "metadata": {},
   "source": [
    "## Import Libraries & Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9323bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a232ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV files into data frames\n",
    "markcamp_clean = pd.read_csv('markcamp_clean.csv')  \n",
    "onlineretail_clean = pd.read_csv('onlineretail_clean.csv')  \n",
    "custseg_clean = pd.read_csv('custseg_clean.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebda33e",
   "metadata": {},
   "source": [
    "## Ensure CustomerID column contains sales from actual customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c315d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the list of IDs from markcamp_clean\n",
    "ids = markcamp_clean['ID'].tolist()\n",
    "\n",
    "# Replace 'CustomerID' in 'onlineretail_clean' with 'CustomerIDs' from the 'markcamp_clean' data set\n",
    "onlineretail_clean['CustomerID'] = onlineretail_clean['CustomerID'].apply(lambda x: random.choice(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ad8d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename ID column\n",
    "markcamp_clean.rename(columns={'ID': 'CustomerID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f8cb53",
   "metadata": {},
   "source": [
    "## Add 'CustomerID' column to 'custseg_clean' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "807b0f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the list of IDs to ensure uniqueness\n",
    "unique_ids = np.random.permutation(markcamp_clean['CustomerID'].tolist())\n",
    "\n",
    "# Calculate the number of additional IDs needed\n",
    "num_additional_ids = 51000 - len(unique_ids)\n",
    "\n",
    "# Generate additional fake IDs\n",
    "additional_fake_ids = np.arange(1, num_additional_ids + 1) + np.max(unique_ids)\n",
    "\n",
    "# Combine unique IDs from markcamp_clean['ID'] with additional system-generated IDs\n",
    "all_ids = np.concatenate((unique_ids, additional_fake_ids))\n",
    "\n",
    "# Shuffle all_ids to ensure randomness\n",
    "shuffled_ids = np.random.permutation(all_ids)\n",
    "\n",
    "# Assign the shuffled CustomerIDs to a new column in custseg_clean\n",
    "custseg_clean.insert(0, 'CustomerID', shuffled_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7289d6",
   "metadata": {},
   "source": [
    "## Merge 'markcamp_clean' & 'custseg_clean' datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c1cf6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Customer Count: 51000\n"
     ]
    }
   ],
   "source": [
    "# Verify individual unique IDs have been assigned to each customer\n",
    "unique_customerseg_count = custseg_clean['CustomerID'].nunique()\n",
    "print(\"Unique Customer Count:\", unique_customerseg_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c38b0cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Customer Count: 2216\n"
     ]
    }
   ],
   "source": [
    "unique_customer_count = onlineretail_clean['CustomerID'].nunique()\n",
    "print(\"Unique Customer Count:\", unique_customer_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e4592ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge custseg_clean with markcamp_clean on 'CustomerID'\n",
    "custseg_clean = pd.merge(custseg_clean, markcamp_clean, on='CustomerID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bdaaeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51000, 45)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custseg_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54206a92",
   "metadata": {},
   "source": [
    "## Fill profile data to ensure dataset is complete "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78669527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unwanted columns\n",
    "columns_to_delete = [\n",
    "    'MntFishProducts', 'MntFruits', 'MntGoldProds', 'MntMeatProducts', \n",
    "    'MntSweetProducts', 'MntWines', 'NumCatalogPurchases', 'NumDealsPurchases',\n",
    "    'NumStorePurchases', 'NumWebPurchases']\n",
    "\n",
    "# Drop the specified columns\n",
    "custseg_clean.drop(columns=columns_to_delete, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91dfdbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data ranges for each column\n",
    "data_ranges = {\n",
    "    'Education': ['2n Cycle', 'Basic', 'Graduation', 'Master', 'PhD'],\n",
    "    'Income': range(1500, 750001),\n",
    "    'Kidhome': range(3),\n",
    "    'Marital_Status': ['Absurd', 'Alone', 'Divorced', 'Married', 'Single', 'Together', 'Widow', 'YOLO'],\n",
    "    'NumWebVisitsMonth': range(21),  \n",
    "    'Recency': range(100),\n",
    "    'Response': [0, 1],\n",
    "    'Teenhome': range(3),\n",
    "    'Year_Birth': range(1940, 1997)\n",
    "}\n",
    "\n",
    "# Iterate over each column and populate with random data\n",
    "for column, values in data_ranges.items():\n",
    "    custseg_clean[column] = np.random.choice(values, size=len(custseg_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc754f45",
   "metadata": {},
   "source": [
    "## Create 'demographic_data' & 'geographic_data' datasets from 'custseg_clean' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c585ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic Data Set:\n",
      "(51000, 19)\n",
      "\n",
      "Geographic Data Set:\n",
      "(51000, 14)\n"
     ]
    }
   ],
   "source": [
    "# Demographic Data Set\n",
    "demographic_columns = ['CustomerID', 'first_name', 'last_name', 'title', 'gender', 'email',\n",
    "                       'company_name', 'department', 'job_title','job_category', 'language', \n",
    "                       'university', 'linkedin_skill', 'Education', 'Income', 'Kidhome', \n",
    "                       'Marital_Status', 'Teenhome', 'Year_Birth']\n",
    "\n",
    "demographic_data = custseg_clean[demographic_columns]\n",
    "\n",
    "# Geographic Data Set\n",
    "geographic_columns = ['CustomerID', 'city', 'country', 'country_code', 'region', 'latitude', 'longitude',\n",
    "                      'phone', 'street_address', 'street_name', 'street_number','street_suffix', \n",
    "                      'time_zone', 'ip_address']\n",
    "\n",
    "geographic_data = custseg_clean[geographic_columns]\n",
    "\n",
    "# Printing first few rows of each set\n",
    "print(\"Demographic Data Set:\")\n",
    "print(demographic_data.shape)\n",
    "\n",
    "print(\"\\nGeographic Data Set:\")\n",
    "print(geographic_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dad490",
   "metadata": {},
   "source": [
    "## Validate Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a7dab55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InvoiceNo      0\n",
      "StockCode      0\n",
      "Description    0\n",
      "Quantity       0\n",
      "InvoiceDate    0\n",
      "UnitPrice      0\n",
      "CustomerID     0\n",
      "Country        0\n",
      "TotalPrice     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count null values in each column\n",
    "null_counts_online = onlineretail_clean.isnull().sum()\n",
    "\n",
    "# Display the null counts\n",
    "print(null_counts_online)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57b15145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID          0\n",
      "first_name          0\n",
      "last_name           0\n",
      "title               0\n",
      "gender              0\n",
      "email               0\n",
      "company_name        0\n",
      "department          0\n",
      "job_title           0\n",
      "job_category      445\n",
      "language            0\n",
      "university          0\n",
      "linkedin_skill      0\n",
      "Education           0\n",
      "Income              0\n",
      "Kidhome             0\n",
      "Marital_Status      0\n",
      "Teenhome            0\n",
      "Year_Birth          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count null values in each column\n",
    "null_counts_demographic = demographic_data.isnull().sum()\n",
    "\n",
    "# Display the null counts\n",
    "print(null_counts_demographic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "452834d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID         0\n",
      "city               0\n",
      "country            0\n",
      "country_code      34\n",
      "region             0\n",
      "latitude           0\n",
      "longitude          0\n",
      "phone              0\n",
      "street_address     0\n",
      "street_name        0\n",
      "street_number      0\n",
      "street_suffix      0\n",
      "time_zone          0\n",
      "ip_address         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count null values in each column\n",
    "null_counts_geographic = geographic_data.isnull().sum()\n",
    "\n",
    "# Display the null counts\n",
    "print(null_counts_geographic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "657852bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique CustomerIDs: 2216\n"
     ]
    }
   ],
   "source": [
    "unique_customer_count = onlineretail_clean['CustomerID'].nunique()\n",
    "print(\"Number of unique CustomerIDs:\", unique_customer_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a6bbfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique CustomerIDs: 51000\n"
     ]
    }
   ],
   "source": [
    "unique_customer_count = demographic_data['CustomerID'].nunique()\n",
    "print(\"Number of unique CustomerIDs:\", unique_customer_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "832b532e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique CustomerIDs: 51000\n"
     ]
    }
   ],
   "source": [
    "unique_customer_count = geographic_data['CustomerID'].nunique()\n",
    "print(\"Number of unique CustomerIDs:\", unique_customer_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8d3d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write dataframes to csv files\n",
    "# onlineretail_clean.to_csv('onlineretail_clean.csv', index=False)\n",
    "\n",
    "# demographic_data.to_csv('custseg_clean.csv', index=False)\n",
    "\n",
    "# geographic_data.to_csv('markcamp_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
